import FirecrawlApp from '@mendable/firecrawl-js';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { NextResponse } from 'next/server';

export async function POST(req: Request) {
  try {
    const { storeName, location } = await req.json();
    const query = `${location} ${storeName} í›„ê¸° ë¦¬ë·°`;

    console.log(`\nğŸ¥ [ì§„ë‹¨ ëª¨ë“œ] "${query}" ë¶„ì„ ì‹œì‘...`);

    const apiKey = process.env.FIRECRAWL_API_KEY;
    const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");
    const firecrawl = new FirecrawlApp({ apiKey: apiKey });

    // 1. ê²€ìƒ‰ (ìƒìœ„ 30ê°œë§Œ ë¹ ë¥´ê²Œ í™•ì¸)
    const searchResponse = await firecrawl.search(query, { limit: 30 });
    const searchResults = (searchResponse as any).data || (searchResponse as any).web || [];

    // 2. ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ (ê°€ê²Œ ì´ë¦„ì´ ì œëª©/ë‚´ìš©ì— ì–¼ë§ˆë‚˜ í¬í•¨ë˜ì—ˆëŠ”ê°€?)
    const mentionCount = searchResults.length;
    
    // 3. AIì—ê²Œ ì„±ì í‘œ ì‘ì„± ìš”ì²­
    // ê²€ìƒ‰ëœ ë°ì´í„°ì˜ ìš”ì•½ë³¸ì„ AIì—ê²Œ ë˜ì ¸ì¤ë‹ˆë‹¤.
    const contextData = JSON.stringify(searchResults.map((item: any) => ({
      title: item.title,
      desc: item.description,
      url: item.url
    })));

    const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash-exp" });
    
    const prompt = `
      ë„ˆëŠ” 'AI ê²€ìƒ‰ ìµœì í™”(GEO) ì»¨ì„¤í„´íŠ¸'ì•¼.
      í´ë¼ì´ì–¸íŠ¸ ê°€ê²Œ ì´ë¦„: "${storeName}" (${location})
      
      ì•„ë˜ëŠ” ê²€ìƒ‰ ì—”ì§„(êµ¬ê¸€/ë¹™)ì—ì„œ ì´ ê°€ê²Œë¥¼ ê²€ìƒ‰í–ˆì„ ë•Œ ë‚˜ì˜¤ëŠ” ìƒìœ„ 30ê°œ ê²°ê³¼ ë°ì´í„°ì•¼.
      ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëƒ‰ì •í•˜ê²Œ ì§„ë‹¨ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜.

      **ë°ì´í„°:**
      ${contextData}

      **ì‘ì„± ì–‘ì‹ (JSON):**
      {
        "score": 0~100 ì‚¬ì´ ìˆ«ì (ë…¸ì¶œì´ ë§ê³  ì •í™•í• ìˆ˜ë¡ ê³ ë“ì , ê²°ê³¼ê°€ ì—†ìœ¼ë©´ 0ì ),
        "rank_status": "ê²€ìƒ‰ ê²°ê³¼ ${mentionCount}ê±´ ë°œê²¬ë¨ (ìƒìœ„ê¶Œ ë…¸ì¶œ ìƒíƒœ)",
        "summary": "í•œì¤„ ìš”ì•½ (ì˜ˆ: ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë¦¬ë·°ëŠ” ë§ìœ¼ë‚˜ ìµœì‹  ê¸€ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.)",
        "details": [
          "ë¶„ì„ ë‚´ìš© 1 (ì¥ì )",
          "ë¶„ì„ ë‚´ìš© 2 (ë‹¨ì /ë¬¸ì œì )",
          "ë¶„ì„ ë‚´ìš© 3 (AIê°€ ì¸ì‹í•˜ëŠ” ê°€ê²Œ ì´ë¯¸ì§€)"
        ],
        "solution": "êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆ 1ê°€ì§€ (ì˜ˆ: 'ê°•ë¦‰ ë¶•ì–´ë¹µ ë§›ì§‘' í‚¤ì›Œë“œë¡œ ë¸”ë¡œê·¸ 3ê°œ ë°°í¬ ì‹œê¸‰)"
      }
    `;

    const result = await model.generateContent(prompt);
    const responseText = await result.response.text();
    
    // JSON íŒŒì‹±
    let report;
    try {
      const cleanText = responseText.replace(/```json|```/g, "").trim();
      report = JSON.parse(cleanText);
    } catch (e) {
      report = { 
        score: 0, 
        rank_status: "ë¶„ì„ ì‹¤íŒ¨", 
        summary: "AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", 
        details: [], 
        solution: "ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”." 
      };
    }

    console.log(`âœ… ì§„ë‹¨ ì™„ë£Œ: ì ìˆ˜ ${report.score}ì `);
    return NextResponse.json({ success: true, report });

  } catch (error: any) {
    console.error(error);
    return NextResponse.json({ success: false, error: error.message }, { status: 500 });
  }
}